{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3430cf88-c249-4d22-8dd1-a8503fccc3e3",
   "metadata": {},
   "source": [
    "# What Do You See? Enhancing Zero-Shot Image Classification with Multimodal Large Language Models\n",
    "\n",
    "Authors: Abdelrahman Abdelhamed, Mahmoud Afifi, Alec Go\n",
    "\n",
    "Large language models (LLMs) has been effectively used for many computer vision tasks, including image classification. In this paper, we present a simple yet effective approach for zero-shot image classification using multimodal LLMs. By employing multimodal LLMs, we generate comprehensive textual representations from input images. These textual representations are then utilized to generate fixed-dimensional features in a cross-modal embedding space. Subsequently, these features are fused together to perform zero-shot classification using a linear classifier. Our method does not require prompt engineering for each dataset; instead, we use a single, straightforward, set of prompts across all datasets. We evaluated our method on several datasets, and our results demonstrate its remarkable effectiveness, surpassing benchmark accuracy on multiple datasets. On average over ten benchmarks, our method achieved an accuracy gain of 4.1 percentage points, with an increase of 6.8 percentage points on the ImageNet dataset, compared to prior methods. Our findings highlight the potential of multimodal LLMs to enhance computer vision tasks such as zero-shot image classification, offering a significant improvement over traditional methods.\n",
    "\n",
    "\n",
    "https://arxiv.org/abs/2405.15668"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10528529-fb3a-4e1a-b121-fd61063a889f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain langchain-aws langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b097fbcc-e72c-42c1-80c7-7fa35d3a2837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AWS_REGION = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9a978b81-1681-414e-80d6-4ba5fda772af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import io\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from langchain_aws.chat_models import ChatBedrock\n",
    "from langchain_aws.embeddings import BedrockEmbeddings\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.language_models import BaseChatModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea597ae9-6f0d-401c-86d5-246f1a84b919",
   "metadata": {},
   "source": [
    "Let's, first of all, create some abstractions that will make our implementation very similar to that of the original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "59975460-4741-4439-b4fc-880c4932031e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _encode_image(uri: str) -> str:\n",
    "    \"\"\"Get base64 string from image URI.\"\"\"\n",
    "    if isinstance(uri, io.BytesIO):\n",
    "        uri.seek(0)\n",
    "        return base64.b64encode(uri.read()).decode(\"utf-8\")\n",
    "\n",
    "    with open(uri, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "class Encoder:\n",
    "    embeddings: Embeddings\n",
    "    dimensions: int\n",
    "    \n",
    "    def __init__(self, embeddings: Embeddings, dimensions: int = 1024):\n",
    "        self.embeddings = embeddings\n",
    "        self.dimensions = dimensions\n",
    "    \n",
    "    def encode_text(self, text) -> list[float]:\n",
    "        return np.array(self.embeddings.embed_query(text))\n",
    "    \n",
    "    def encode_image(self, image) -> list[float]:\n",
    "        b64_text = _encode_image(image)\n",
    "\n",
    "        payload = {\"inputImage\": b64_text}\n",
    "        body = json.dumps(payload)\n",
    "        \n",
    "        try:\n",
    "            response = self.embeddings.client.invoke_model(\n",
    "                body=body, modelId=self.embeddings.model_id, accept=\"application/json\", contentType=\"application/json\"\n",
    "            )\n",
    "\n",
    "            vector_json = json.loads(response[\"body\"].read().decode(\"utf8\"))\n",
    "\n",
    "            return np.array(vector_json[\"embedding\"])\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error raised by inference endpoint: {e}\")\n",
    "    \n",
    "    @property\n",
    "    def output_feature_length(self,) -> int:\n",
    "        return self.dimensions\n",
    "        \n",
    "\n",
    "class LLM:\n",
    "    chat_model: BaseChatModel\n",
    "    \n",
    "    def __init__(self, chat_model):\n",
    "        self.chat_model = chat_model\n",
    "    \n",
    "    def process(self, prompt: str | tuple[str, str | io.BytesIO], temperature: float = 0) -> str:\n",
    "        self.chat_model.model_kwargs[\"temperature\"] = temperature\n",
    "        \n",
    "        if isinstance(prompt, str):\n",
    "            chain = self.chat_model | StrOutputParser()\n",
    "            \n",
    "            return chain.invoke(prompt)\n",
    "        \n",
    "        sys_prompt, image = prompt\n",
    "        \n",
    "        final_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", sys_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"input\")\n",
    "        ])\n",
    "        \n",
    "        chain = final_prompt | self.chat_model | StrOutputParser()\n",
    "        \n",
    "        return chain.invoke({\"input\": [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\"type\": \"base64\", \"media_type\": \"image/jpeg\", \"data\": _encode_image(image)},\n",
    "                    },\n",
    "                ]\n",
    "            ),\n",
    "        ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e0cd7e66-b2a8-40f7-b2a3-ea366f8ca688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto_session = boto3.session.Session(region_name=AWS_REGION)\n",
    "\n",
    "bedrock_client = boto_session.client(\n",
    "    \"bedrock-runtime\",\n",
    "    config=Config(\n",
    "        connect_timeout=120,\n",
    "        read_timeout=120,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"adaptive\",\n",
    "        },\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "55d2f6b7-9ee1-4f70-aa32-2074f9ea926f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "claude = ChatBedrock(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    model_kwargs={},\n",
    ")\n",
    "\n",
    "titan_embeddings = BedrockEmbeddings(client=bedrock_client, model_id=\"amazon.titan-embed-image-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ecbdbf96-43af-4c93-b452-7f26c22a491e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(titan_embeddings, 1024)\n",
    "llm = LLM(claude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd59f8e-25a4-40f4-ac93-bb4189426e8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Now, on to the implementation of the paper\n",
    "\n",
    "I strived to be as close as possible to the implementation on page 12 of the arxiv paper (\"Code 1\" listing). However, I replaced tensorflow with numpy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "52ede4f3-d352-4a98-abf7-be00df3cf943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classification_p = \"You are given an image and a list of class labels. Classify the image given the class labels. Answer using a single word if possible. Here are the class labels: {classes}\"\n",
    "\n",
    "description_p = \"What do you see? Describe any object precisely, including its type or class.\"\n",
    "\n",
    "class_ps = [\n",
    "    \"Describe what a {class_label} looks like in one or two sentences\",\n",
    "    \"How can you identify a {class_label} in one or two sentences?\",\n",
    "    \"What does a {class_label} look like? Respond with one or two sentences.\",\n",
    "    \"Describe an image from the internet that you know of of a {class_label}. Respond with one or two sentences.\",  # had to change from the original paper, o/w LLM would simply respond \"Sorry, but you did not provide an image...\"\n",
    "    \"A short caption of an image of a {class_label}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bcb10dae-3943-42f2-99b7-f74b453bcbec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_classifier(class_names, k: int = 5):\n",
    "    assert k >= len(class_ps)\n",
    "    assert k % len(class_ps) == 0\n",
    "\n",
    "    weights = []\n",
    "    \n",
    "    for class_name in tqdm(class_names):\n",
    "        class_name_feature = encoder.encode_text(class_name)\n",
    "        template_feature = encoder.encode_text(f\"A photo of {class_name}\")\n",
    "        \n",
    "        llm_class_description = np.zeros(encoder.output_feature_length)\n",
    "        for _ in (progress_bar := tqdm(range(k // len(class_ps)))):\n",
    "            progress_bar.set_description(f\"class: {class_name}\")\n",
    "            for class_p in class_ps:\n",
    "                llm_class_feature = llm.process(class_p.format(class_label=class_name), temperature=0.99)\n",
    "                print(llm_class_feature.split('\\n', 1)[0])\n",
    "                llm_class_description += encoder.encode_text(llm_class_feature)\n",
    "        llm_class_description /= k\n",
    "        \n",
    "        class_feature = class_name_feature + template_feature + llm_class_description\n",
    "        normalized_class_feature = class_feature / np.linalg.norm(class_feature)\n",
    "        \n",
    "        weights.append(np.squeeze(normalized_class_feature))\n",
    "        \n",
    "    model = {\"weights\": np.transpose(np.array(weights)), \"class_names\": class_names}\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8793b605-b689-444f-bea1-3171a1db998b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12cc6f571f14790bd84c0a2952b3ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9046c6c274c2435fbaf31de3d9a12f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plastic is a synthetic material made from a wide range of organic polymers that can be molded into various shapes and forms. It can have different colors, textures, and levels of transparency, ranging from completely clear to opaque, and can be rigid or flexible depending on its composition and intended use.\n",
      "You can identify different types of plastics by looking at the resin identification code, which is a number from 1 to 7 inside a triangle symbol stamped or printed on the plastic item.\n",
      "Plastic typically has a smooth, shiny surface and can come in various colors, textures, and transparencies depending on its composition and intended use.\n",
      "I don't actually have access to specific images from the internet. As an AI assistant without the ability to browse the web, I can only analyze and describe images that are provided to me directly.\n",
      "Here are some potential short captions for an image of plastic:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde11f182e7448fdb2bed123fe0a7792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A metal typically has a lustrous, shiny appearance that reflects light, giving it a distinctive metallic gleam. Metals can vary in color, ranging from the silvery hues of aluminum and steel to the warm yellow tones of gold or the reddish-brown of copper.\n",
      "You can identify a metal by its characteristic properties such as a lustrous appearance, malleability (ability to be hammered into thin sheets), ductility (ability to be drawn into wires), and high electrical and thermal conductivity.\n",
      "A metal typically has a shiny, lustrous appearance and a grayish color, though the exact shade can vary depending on the specific metal. It also has a high density and can conduct heat and electricity well.\n",
      "Here is a one sentence description of an image of metal from the internet:\n",
      "Here are some potential short captions for an image of metal:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a866c7619d8743789acb076b74564689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A paper is a thin, flat material made from compressed plant fibers, typically rectangular or square in shape, with a smooth surface suitable for writing or printing on.\n",
      "To identify a paper in one or two sentences, you can state the title of the paper, the authors, and the publication it appeared in (journal, conference proceedings, etc.). For example: \"The paper 'Title of the Paper' by Author1, Author2, and Author3 was published in the Journal of X Research in 2020.\"\n",
      "A paper typically appears as a thin, flat sheet or rectangular material made from wood pulp or other fibrous materials, usually white or off-white in color.\n",
      "Here is a one sentence description of a well-known image of a paper from the internet: The famous \"This is a Wireframe\" joke image depicts a crudely drawn hand holding up a piece of lined paper with the text \"THIS IS A WIREFRAME\" scribbled on it.\n",
      "Here are some potential short captions for an image of a paper:\n"
     ]
    }
   ],
   "source": [
    "classifier = create_classifier([\"plastic\", \"metal\", \"paper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "569910f6-a85b-4ea4-945a-be33432a2fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify(image, _classifier):\n",
    "    image_feature = encoder.encode_image(image)\n",
    "    image_feature /= np.linalg.norm(image_feature)\n",
    "    \n",
    "    initial_prediction = llm.process((classification_p.format(classes=[\"plastic\", \"metal\", \"paper\"]), image), temperature=0.3)\n",
    "    print(f\"Initial prediction: {initial_prediction}\")\n",
    "    prediction_feature = encoder.encode_text(initial_prediction)\n",
    "    prediction_feature /= np.linalg.norm(prediction_feature)\n",
    "    \n",
    "    image_description = llm.process((description_p, image), temperature=0)\n",
    "    description_feature = encoder.encode_text(image_description)\n",
    "    description_feature /= np.linalg.norm(description_feature)\n",
    "    \n",
    "    query_feature = image_feature + prediction_feature + description_feature\n",
    "    query_feature /= np.linalg.norm(query_feature)\n",
    "    # return query_feature\n",
    "    likelihoods = np.matmul(query_feature, classifier[\"weights\"])\n",
    "    print(likelihoods)\n",
    "    index = np.argmax(likelihoods)\n",
    "    \n",
    "    return classifier[\"class_names\"][np.squeeze(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "00bdbf2a-07ca-4240-9914-9624ace37b39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prediction: The image depicts a plastic bag containing a red-wrapped food item or snack. Based on the class labels provided - 'plastic', 'metal', and 'paper' - the appropriate classification for this image would be plastic, as the primary visible object is a plastic bag or packaging material.\n",
      "[0.59115122 0.50143578 0.54155003]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'plastic'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cashews_plastic = \"./1701029658.jpg\"\n",
    "kitkat_plastic = \"./1709498901.jpg\"\n",
    "\n",
    "result = classify(kitkat_plastic, classifier)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5050d1-6c0c-4d6d-bcdb-56e370c0d05e",
   "metadata": {},
   "source": [
    "## Benchmarking with our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ae5aeab6-96bb-4b3a-b038-63a0b432bad5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prediction: Based on the image and the provided class labels, the material depicted is plastic. The image shows a crumpled red plastic bag or wrapper hanging or suspended against a bluish background.\n",
      "[0.53298613 0.44400442 0.51629422]\n",
      "\u001b[32mFor 1709498901.jpg [kitkat] (expected plastic, got plastic\u001b[0m\n",
      "Initial prediction: Based on the image and the given class labels, the appropriate classification for this image would be metal. The image shows a red aluminum beverage can protruding through a torn piece of paper or cardboard material, indicating the can is made of metal.\n",
      "[0.51483863 0.53598519 0.54020967]\n",
      "\u001b[31mFor 1709498394.jpg [coke can] (expected metal, got paper\u001b[0m\n",
      "Initial prediction: Based on the image, the material that best fits the given class labels is plastic. The image shows a clear plastic bag or wrapping material containing what appears to be a blue plastic bottle or container.\n",
      "[0.64935216 0.49125745 0.54324783]\n",
      "\u001b[32mFor 1709500856.jpg [water bottle] (expected plastic, got plastic\u001b[0m\n",
      "Initial prediction: Based on the image, which shows a crumpled piece of paper or foil containing some candy wrappers or packaging, the appropriate classification from the given labels would be paper.\n",
      "[0.59985473 0.56161044 0.61143294]\n",
      "\u001b[32mFor 1709660526.jpg [toddynho] (expected paper, got paper\u001b[0m\n",
      "Initial prediction: Based on the image and the given class labels, the correct classification for this image is paper. The image shows what appears to be a cardboard or paper container or box that has been opened or torn, with a red plastic or foil item visible inside.\n",
      "[0.54144254 0.47665889 0.55654749]\n",
      "\u001b[31mFor 1701029658.jpg [cashews] (expected plastic, got paper\u001b[0m\n",
      "Initial prediction: Based on the image, the correct classification from the given class labels is paper. The image shows crumpled paper or plastic bags stuffed into a corner, resembling discarded paper or trash.\n",
      "[0.6094619  0.47287001 0.55750472]\n",
      "\u001b[31mFor 1701222618.jpg [ben and jerry's] (expected paper, got plastic\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RED = \"\\033[31m\"  # Red text\n",
    "GREEN = \"\\033[32m\"  # Green text\n",
    "RESET = \"\\033[0m\"  # Reset to default color\n",
    "\n",
    "for image, expected_material, label in [\n",
    "        (\"1709498901.jpg\", \"plastic\", \"kitkat\"),\n",
    "        (\"1709498394.jpg\", \"metal\", \"coke can\"),\n",
    "        (\"1709500856.jpg\", \"plastic\", \"water bottle\"),\n",
    "        (\"1709660526.jpg\", \"paper\", \"toddynho\"),\n",
    "        (\"1701029658.jpg\", \"plastic\", \"cashews\"),\n",
    "        (\"1701222618.jpg\", \"paper\", \"ben and jerry's\"),\n",
    "    ]:\n",
    "    material_type = classify(f\"./trash/{image}\", classifier)\n",
    "    \n",
    "    match = material_type == expected_material\n",
    "    \n",
    "    print(\n",
    "        f\"{GREEN if match else RED}For {image} [{label}] (expected {expected_material}, got {material_type}){RESET}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0becca92-dce8-4fd1-8eb0-7dfe0635be28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
